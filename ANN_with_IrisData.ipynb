{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7grv36g0jathh2g0hUPup",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EricSiq/DeepLearning/blob/main/ANN_with_IrisData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n"
      ],
      "metadata": {
        "id": "o11YYzP55Elx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 1: Define the Neural Network class\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.1):\n",
        "        \"\"\"\n",
        "        Initializes the neural network with specified sizes and learning rate.\n",
        "        Includes basic error handling for input parameters.\n",
        "        \"\"\"\n",
        "        if not all(isinstance(i, int) and i > 0 for i in [input_size, hidden_size, output_size]):\n",
        "            raise TypeError(\"Input, hidden, and output sizes must be positive integers.\")\n",
        "        if not isinstance(learning_rate, (int, float)) or not (0 < learning_rate <= 1):\n",
        "            raise ValueError(\"Learning rate must be a number between 0 and 1.\")\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        # Step 2: Initialize weights and biases randomly\n",
        "        # Weights from input to hidden layer\n",
        "        self.weights_ih = np.random.randn(self.input_size, self.hidden_size) * 0.01\n",
        "        # Biases for hidden layer\n",
        "        self.bias_h = np.zeros((1, self.hidden_size))\n",
        "\n",
        "        # Weights from hidden to output layer\n",
        "        self.weights_ho = np.random.randn(self.hidden_size, self.output_size) * 0.01\n",
        "        # Biases for output layer\n",
        "        self.bias_o = np.zeros((1, self.output_size))\n",
        "\n",
        "\n",
        "    # Step 3: Define the activation functions (Sigmoid and its derivative)\n",
        "    def sigmoid(self, x):\n",
        "        \"\"\"Sigmoid activation function.\"\"\"\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        \"\"\"Derivative of the sigmoid function.\"\"\"\n",
        "        return x * (1 - x)\n",
        "\n",
        "    # Step 4: Implement the feedforward process\n",
        "    def feedforward(self, inputs):\n",
        "        \"\"\"\n",
        "        Passes inputs through the network to get an output.\n",
        "        Performs basic error handling for input shape.\n",
        "        \"\"\"\n",
        "        if inputs.shape[1] != self.input_size:\n",
        "            raise ValueError(f\"Input shape mismatch. Expected {self.input_size} features, got {inputs.shape[1]}.\")\n",
        "\n",
        "        # Calculate hidden layer output\n",
        "        self.hidden_layer_input = np.dot(inputs, self.weights_ih) + self.bias_h\n",
        "        self.hidden_layer_output = self.sigmoid(self.hidden_layer_input)\n",
        "\n",
        "        # Calculate final output\n",
        "        self.output_layer_input = np.dot(self.hidden_layer_output, self.weights_ho) + self.bias_o\n",
        "        self.output = self.sigmoid(self.output_layer_input)\n",
        "\n",
        "        return self.output\n",
        "\n",
        "    # Step 5: Implement the backpropagation process\n",
        "    def backpropagation(self, inputs, targets):\n",
        "        \"\"\"\n",
        "        Calculates and updates weights and biases based on the error.\n",
        "        Performs basic error handling for input shape.\n",
        "        \"\"\"\n",
        "        if targets.shape != self.output.shape:\n",
        "            raise ValueError(f\"Target shape mismatch. Expected {self.output.shape}, got {targets.shape}.\")\n",
        "\n",
        "        # Calculate output layer error\n",
        "        output_error = targets - self.output\n",
        "        output_delta = output_error * self.sigmoid_derivative(self.output)\n",
        "\n",
        "        # Calculate hidden layer error\n",
        "        hidden_error = output_delta.dot(self.weights_ho.T)\n",
        "        hidden_delta = hidden_error * self.sigmoid_derivative(self.hidden_layer_output)\n",
        "\n",
        "        # Update weights and biases for output layer\n",
        "        self.weights_ho += self.hidden_layer_output.T.dot(output_delta) * self.learning_rate\n",
        "        self.bias_o += np.sum(output_delta, axis=0, keepdims=True) * self.learning_rate\n",
        "\n",
        "        # Update weights and biases for hidden layer\n",
        "        self.weights_ih += inputs.T.dot(hidden_delta) * self.learning_rate\n",
        "        self.bias_h += np.sum(hidden_delta, axis=0, keepdims=True) * self.learning_rate\n",
        "\n",
        "    # Step 6: Define the training loop\n",
        "    def train(self, inputs, targets, epochs):\n",
        "        \"\"\"\n",
        "        Trains the network for a specified number of epochs.\n",
        "        Performs basic error handling for input types and shapes.\n",
        "        \"\"\"\n",
        "        if not isinstance(epochs, int) or epochs <= 0:\n",
        "            raise ValueError(\"Epochs must be a positive integer.\")\n",
        "        if not isinstance(inputs, np.ndarray) or not isinstance(targets, np.ndarray):\n",
        "            raise TypeError(\"Inputs and targets must be numpy arrays.\")\n",
        "        if inputs.shape[0] != targets.shape[0]:\n",
        "            raise ValueError(\"Inputs and targets must have the same number of rows.\")\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            self.feedforward(inputs)\n",
        "            self.backpropagation(inputs, targets)\n",
        "\n",
        "            # Print error every 1000 epochs to monitor progress\n",
        "            if (epoch + 1) % 1000 == 0:\n",
        "                loss = np.mean(np.square(targets - self.output))\n",
        "                print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss:.4f}\")\n",
        "\n",
        "    # Step 7: Define a method for making predictions\n",
        "    def predict(self, inputs):\n",
        "        \"\"\"\n",
        "        Makes a prediction for given inputs and returns the class label.\n",
        "        The output is the index of the neuron with the highest activation.\n",
        "        \"\"\"\n",
        "        output = self.feedforward(inputs)\n",
        "        return np.argmax(output, axis=1)"
      ],
      "metadata": {
        "id": "5U1ZmWxg5Db7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkPT_OWe4U70",
        "outputId": "2dd2cb52-8ed0-4cd9-dfe5-96b53b03b87d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preprocessing the Iris dataset...\n",
            "\n",
            "Training the ANN for Iris classification with 10000 epochs...\n",
            "Epoch 1000/10000, Loss: 0.1194\n",
            "Epoch 2000/10000, Loss: 0.1195\n",
            "Epoch 3000/10000, Loss: 0.0106\n",
            "Epoch 4000/10000, Loss: 0.0113\n",
            "Epoch 5000/10000, Loss: 0.0107\n",
            "Epoch 6000/10000, Loss: 0.0106\n",
            "Epoch 7000/10000, Loss: 0.0104\n",
            "Epoch 8000/10000, Loss: 0.0102\n",
            "Epoch 9000/10000, Loss: 0.0100\n",
            "Epoch 10000/10000, Loss: 0.0096\n",
            "Training complete.\n",
            "\n",
            "Evaluating the trained network:\n",
            "Model Accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Main execution block\n",
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        # Step 8: Prepare and preprocess the Iris dataset\n",
        "        print(\"Loading and preprocessing the Iris dataset...\")\n",
        "        iris = load_iris()\n",
        "        X = iris.data\n",
        "        y = iris.target.reshape(-1, 1)\n",
        "\n",
        "        # Normalize the input data to a 0-1 range\n",
        "        X = X / np.max(X, axis=0)\n",
        "\n",
        "        # One-hot encode the target labels for multi-class classification\n",
        "        encoder = OneHotEncoder(sparse_output=False)\n",
        "        y_one_hot = encoder.fit_transform(y)\n",
        "\n",
        "        # Split the dataset into training and testing sets\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n",
        "        y_test_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "        # Step 9: Initialize and train the neural network\n",
        "        # The network has 4 inputs (features), 8 hidden neurons, and 3 outputs (classes)\n",
        "        input_size = X_train.shape[1]\n",
        "        output_size = y_train.shape[1]\n",
        "        ann = NeuralNetwork(input_size=input_size, hidden_size=8, output_size=output_size, learning_rate=0.5)\n",
        "        epochs = 10000\n",
        "\n",
        "        print(f\"\\nTraining the ANN for Iris classification with {epochs} epochs...\")\n",
        "        ann.train(X_train, y_train, epochs)\n",
        "        print(\"Training complete.\")\n",
        "\n",
        "        # Step 10: Evaluate the trained network\n",
        "        print(\"\\nEvaluating the trained network:\")\n",
        "        predictions = ann.predict(X_test)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = np.mean(predictions == y_test_labels) * 100\n",
        "        print(f\"Model Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    except (TypeError, ValueError) as e:\n",
        "        print(f\"\\nAn error occurred during network setup or training: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn unexpected error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a6ltjrK45GEB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}